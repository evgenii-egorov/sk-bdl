{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This animation is to illustrate convexity in mean-parameters of the conjugate likelihood and prior.\n",
    "Note, that posterior mean is always between MLE and prior mean.\n",
    "\n",
    "Author: [Evgenii Egorov](mailto:egorov.evgenyy@ya.ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "class BetaPosterior:\n",
    "    def __init__(self, prior):\n",
    "        self.tau = prior\n",
    "        \n",
    "    def update(self, X): \n",
    "        self.tau[0] += np.sum(X)\n",
    "        self.tau[1] += X.shape[0] - np.sum(X)\n",
    "\n",
    "    def sample(self, size):\n",
    "        return stats.beta.rvs(*self.tau, size=size)\n",
    "    \n",
    "    def mean(self):\n",
    "        return (self.tau[0]) / (self.tau[0] + self.tau[1])\n",
    "    \n",
    "class BetaMLE:\n",
    "    def __init__(self):\n",
    "        self.N = 0.\n",
    "        self.sum_stat = 0.\n",
    "    \n",
    "    def update(self, X):\n",
    "        self.N += X.shape[0]\n",
    "        self.sum_stat += np.sum(X)\n",
    "    \n",
    "    def mle(self):\n",
    "        return self.sum_stat / self.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_true = 0.1\n",
    "batch_size = 1\n",
    "epoch_num = 350\n",
    "\n",
    "prior_params = np.array([1., 1.])\n",
    "\n",
    "p_posterior = BetaPosterior(prior_params.copy())\n",
    "p_mle = BetaMLE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_posterior = BetaPosterior(prior_params.copy())\n",
    "p_mle = BetaMLE()\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "mle_ls = []\n",
    "posterior_ls = []\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    X_sample = stats.bernoulli.rvs(p_true, size=batch_size)\n",
    "    \n",
    "    p_mle.update(X_sample)\n",
    "    p_posterior.update(X_sample)\n",
    "    \n",
    "    mle_ls.append(p_mle.mle())\n",
    "    posterior_ls.append(p_posterior.mean())\n",
    "    \n",
    "    p_sample = p_posterior.sample(500)\n",
    "    y_max = np.max(np.histogram(p_sample)[0])\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.hist(p_sample, alpha=0.3);\n",
    "    plt.vlines(mle_ls[-1], 0, y_max, color='green', label='mle');\n",
    "    plt.vlines(posterior_ls[-1], 0, y_max, color='orange', label='posterior mean');\n",
    "    plt.vlines(p_true, 0, y_max, color='red', label='true');\n",
    "    plt.vlines(prior_params[0] / (prior_params[0] + prior_params[1]), 0, y_max, color='black', label='prior mean')\n",
    "    plt.legend(loc=2);\n",
    "    plt.xlim(0, 0.7)\n",
    "    plt.yticks(ticks=[i*20 for i in range(5)])\n",
    "    plt.grid();\n",
    "    \n",
    "    plt.show();\n",
    "    plt.pause(0.3);\n",
    "    clear_output(wait=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
