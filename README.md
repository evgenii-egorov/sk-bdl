# Bayesian Machine Learning 
This is materials on Bayesian Machine Learning that [I](evgenii-egorov.github.io) developed during autumns in 2018, 2019, 2020.
Despite that it was three times, mistakes and misprints are presented almost surely. 
I would like to thank [Anna Kuzina](https://akuzina.github.io) and [Ruslan Kostoev](https://scholar.google.ru/citations?user=J6DmVZ0AAAAJ)
for their thoughtful comments and help.

For each class there is some combination of following materials:
- slides: contain some theory, sometimes derivations for particular examples
- notes: contain derivations of the discussed topic for particular model or exp. family case
- notebooks: contain illustrative experiment or implementation of the model of the discussed topic
- whiteboard\& video: zoom-record of actual seminar and live-made notes

| #  | Topic   | Materials  | Whiteboard | Video|                                                                                                                                                               
|----|---------|------------------|------------|--------|
| 1 | MaxEnt, Exponential Families Mean and Natural Parameters|[slides](/seminar_1/slides/2020_bmml_1.pdf), [notebook](/seminar_1/notebook/BetaAnimation.ipynb)|[whiteboard](/seminar_1/whiteboard/whiteboard_sk_01_09_Bayes.pdf)|TBA|
| 2 | Bayesian Linear Regression: RVM and Sequential Updates| [slides](seminar_2/slides/rvm_alfa_beta_upd.pdf), [notebooks RVM](seminar_2/notebook/RVMReg-Solutions.ipynb), [notebooks RVM](seminar_2/notebook/Sequential_Solutions.ipynb)| None | TBA |
| 3 | Conjugate Priors | [slides](seminar_3/slides/2020_bmml_seminar_3_0409.pdf) | [whiteboard](seminar_3/whiteboard/whiteboard_seminar_0409.pdf)|TBA|
| 4,5 | Approximation Inference for Special Non-Conjugate Models | [slides](seminar_4_5/slides/bmml_4-5.pdf) | [whiteboard4](seminar_4_5/whiteboard/whiteboard_sk_bml_seminar_4_0809.pdf), [whiteboard5](seminar_4_5/whiteboard/sk_bmml_seminar5_10-09.pdf)|TBA|
| 6 | EM Algorithm (and Exp. Families) | [slides](seminar_6/slides/2020_sk_bml_6.pdf), [notes for exp. families](/seminar_6/slides/expfamily_derivation_upd.pdf) | [whiteboard](seminar_6/whiteboard/sk_bml_whiteboard_11-09.pdf)|TBA|
| 7 | Mean Field (and Exp. Families)  | [slides](seminar_7/slides/2020_sk_bml_7.pdf), [derivations for simple models and exp. families](seminar_7/slides/sk_bml_7_notes.pdf) | [whiteboard](seminar_7/whiteboard/whiteboard_sk_bml_15.pdf)|TBA|
| 8 | Reinforce and Reparametrization  | [slides](seminar_8/slides/2020_sk_bml_8.pdf), [notebook](seminar_8/notebook/illustration_sem8.ipynb) | [whiteboard](seminar_8/whiteboard/whiteboard_sk_bml_17_09.pdf)|TBA|
| 12 | Variational Dropout |[notebook](/seminar_12/notebook/sem12_var_ard_dropout_FULL.ipynb) | [whiteboard](/seminar_12/whiteboard/sk_bml_25_09.pdf)|TBA|
| 14| Normalizing Flows | [slides](/seminar_14/slides/Seminar14_NF.pdf), [notebook](/seminar_14/notebook/Sem14_NF_demo.ipynb) |None |TBA|
| HW | EM Mixture for Robust PCA derivation | [notes ](seminar_15/slides/Assignment_2_theory_solution.pdf) | None |TBA|
| 18 | MCMC | [notebook](seminar_18/notebook/MCMC.ipynb) | None|TBA|

I suppose most visitors to this page are in seek of materials to learn on Bayesian machine learning.
Hence, I could not avoid the recommendation of the [Deep Bayes](deepbayes.ru) materials.
